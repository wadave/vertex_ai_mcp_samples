{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2025 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Use Gemini 2.5 Pro to create MCP Server\n",
        "\n",
        "\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/wadave/vertex_ai_mcp_samples/blob/main/create_mcp_server_by_gemini.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  \n",
        "  \n",
        "  \n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/wadave/vertex_ai_mcp_samples/blob/main/create_mcp_server_by_gemini.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>\n",
        "\n",
        "<b>Share to:</b>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/notebook_template.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/notebook_template.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/notebook_template.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/notebook_template.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/notebook_template.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84f0f73a0f76"
      },
      "source": [
        "| Author(s) |\n",
        "| --- |\n",
        "| [Dave Wang](https://github.com/wadave) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook demonstrates how to use Gemini 2.5 pro create MCP server codes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prerequisites\n",
        "Gemini 2.5 Pro is currently only available via Google API/App or AI Studio(3/30/2025)\n",
        "- Get a Google API key\n",
        "- Save the Google API as 'google_api_key' in your google cloud secret manager (optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61RBz8LLbxCR"
      },
      "source": [
        "## Get started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Install Google Gen AI SDK and other required packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFy3H3aPgx12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet google-genai google-cloud-secret-manager mcp geopy black google-cloud-bigquery"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWOrTJ3gx13"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you're running this notebook on Google Colab, run the cell below to authenticate your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyKGtVQjgx13"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4l8DTdWgPY"
      },
      "source": [
        "### Set Google Cloud project information\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Nqwi-5ufWp_B"
      },
      "outputs": [],
      "source": [
        "# Use the environment variable if the user doesn't provide Project ID.\n",
        "import os\n",
        "\n",
        "from google import genai\n",
        "\n",
        "PROJECT_ID = \"[your-project-id]\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
        "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
        "\n",
        "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n",
        "\n",
        "#client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.cloud import secretmanager\n",
        "from google import genai\n",
        "import datetime\n",
        "\n",
        "from google.genai.types import (\n",
        "    CreateBatchJobConfig,\n",
        "    CreateCachedContentConfig,\n",
        "    EmbedContentConfig,\n",
        "    FunctionDeclaration,\n",
        "    GenerateContentConfig,\n",
        "    Part,\n",
        "    SafetySetting,\n",
        "    Tool,\n",
        ")\n",
        "\n",
        "import json\n",
        "from mcp import ClientSession, StdioServerParameters\n",
        "from mcp.client.stdio import stdio_client\n",
        "from typing import Any, List\n",
        "import asyncio\n",
        "from google.genai import types\n",
        "from typing import List\n",
        "from util import(\n",
        "    access_secret_version,\n",
        "    get_url_content,\n",
        "    format_python\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option 1 Get Google API key from secret manager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO you need to create a 'google_api_key' and save it in secret manager\n",
        "api_key = access_secret_version(PROJECT_ID, secret_id=\"google_api_key\", version_id=\"latest\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option 2 Get Google API key from environment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# api_key=os.getenv(\"GEMINI_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO(developer): Update below line\n",
        "API_KEY = api_key\n",
        "\n",
        "client = genai.Client(api_key=API_KEY)\n",
        "\n",
        "MODEL25_ID = \"gemini-2.5-pro-exp-03-25\" #This model is only for MCP server code generation. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get system instruction context info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The URL you want to fetch\n",
        "url = 'https://modelcontextprotocol.io/quickstart/server'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully fetched content\n"
          ]
        }
      ],
      "source": [
        "reference_content = get_url_content(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "class response_schema(BaseModel):\n",
        "    python_code: str\n",
        "    description: str\n",
        "    \n",
        "system_instruction = f\"\"\"\n",
        "  You are an MCP server export.\n",
        "  Your mission is to write python code for MCP server.\n",
        "  Here's the MCP server development guide and example\n",
        "  {reference_content}\n",
        "  \n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_mcp_server(prompt): \n",
        "    response = client.models.generate_content(\n",
        "        model=MODEL25_ID,\n",
        "        contents=prompt,\n",
        "        config=GenerateContentConfig(\n",
        "            system_instruction=system_instruction,\n",
        "            response_mime_type=\"application/json\",\n",
        "            response_schema=response_schema,\n",
        "        ),\n",
        "    )\n",
        "    \n",
        "    return response.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Gemini Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define gemini agent loop\n",
        "MODEL_ID = \"gemini-2.5-pro-exp-03-25\" # You could use a different model\n",
        "async def agent_loop(prompt: str, client: genai.Client, session: ClientSession):\n",
        "    contents = [types.Content(role=\"user\", parts=[types.Part(text=prompt)])]\n",
        "    # Initialize the connection\n",
        "    await session.initialize()\n",
        "    \n",
        "    # --- 1. Get Tools from Session and convert to Gemini Tool objects ---\n",
        "    mcp_tools = await session.list_tools()\n",
        "    tools = types.Tool(function_declarations=[\n",
        "        {\n",
        "            \"name\": tool.name,\n",
        "            \"description\": tool.description,\n",
        "            \"parameters\": tool.inputSchema,\n",
        "        }\n",
        "        for tool in mcp_tools.tools\n",
        "    ])\n",
        "    \n",
        "    # --- 2. Initial Request with user prompt and function declarations ---\n",
        "    response = await client.aio.models.generate_content(\n",
        "        model=MODEL_ID,  # Or your preferred model supporting function calling\n",
        "        contents=contents,\n",
        "        config=types.GenerateContentConfig(\n",
        "            temperature=0,\n",
        "            tools=[tools],\n",
        "        ),  # Example other config\n",
        "    )\n",
        "    \n",
        "    # --- 3. Append initial response to contents ---\n",
        "    contents.append(response.candidates[0].content)\n",
        "\n",
        "    # --- 4. Tool Calling Loop ---            \n",
        "    turn_count = 0\n",
        "    max_tool_turns = 5\n",
        "    while response.function_calls and turn_count < max_tool_turns:\n",
        "        turn_count += 1\n",
        "        tool_response_parts: List[types.Part] = []\n",
        "\n",
        "        # --- 4.1 Process all function calls in order and return in this turn ---\n",
        "        for fc_part in response.function_calls:\n",
        "            tool_name = fc_part.name\n",
        "            args = fc_part.args or {}  # Ensure args is a dict\n",
        "            print(f\"Attempting to call MCP tool: '{tool_name}' with args: {args}\")\n",
        "\n",
        "            tool_response: dict\n",
        "            try:\n",
        "                # Call the session's tool executor\n",
        "                tool_result = await session.call_tool(tool_name, args)\n",
        "                print(f\"MCP tool '{tool_name}' executed successfully.\")\n",
        "                if tool_result.isError:\n",
        "                    tool_response = {\"error\": tool_result.content[0].text}\n",
        "                else:\n",
        "                    tool_response = {\"result\": tool_result.content[0].text}\n",
        "            except Exception as e:\n",
        "                tool_response = {\"error\":  f\"Tool execution failed: {type(e).__name__}: {e}\"}\n",
        "            \n",
        "            # Prepare FunctionResponse Part\n",
        "            tool_response_parts.append(\n",
        "                types.Part.from_function_response(\n",
        "                    name=tool_name, response=tool_response\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # --- 4.2 Add the tool response(s) to history ---\n",
        "        contents.append(types.Content(role=\"user\", parts=tool_response_parts))\n",
        "        print(f\"Added {len(tool_response_parts)} tool response parts to history.\")\n",
        "\n",
        "        # --- 4.3 Make the next call to the model with updated history ---\n",
        "        print(\"Making subsequent API call with tool responses...\")\n",
        "        response = await client.aio.models.generate_content(\n",
        "            model=MODEL_ID,\n",
        "            contents=contents,  # Send updated history\n",
        "            config=types.GenerateContentConfig(\n",
        "                temperature=1.0,\n",
        "                tools=[tools],\n",
        "            ),  # Keep sending same config\n",
        "        )\n",
        "        contents.append(response.candidates[0].content)\n",
        "\n",
        "    if turn_count >= max_tool_turns and response.function_calls:\n",
        "        print(f\"Maximum tool turns ({max_tool_turns}) reached. Exiting loop.\")\n",
        "\n",
        "    print(\"MCP tool calling loop finished. Returning final response.\")\n",
        "    # --- 5. Return Final Response ---\n",
        "    return response\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 1:  Create MCP Server for Google Cloud BigQuery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "  Please create an MCP server code for google cloud big query. It has two tools. One is to list tables for all datasets, the other is to describe a table. Google cloud project id and location will be provided for use. please use project id to access big query client.\n",
        "  \n",
        "  Return Python code within a JSON object formatted exactly as: {'python_code':    'your_generated_code', 'description':'your description'}\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "response_text= generate_mcp_server(prompt)\n",
        "python_code=json.loads(response_text)['python_code']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Format python code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully formatted the code and saved it to 'bq_script.py'\n"
          ]
        }
      ],
      "source": [
        "format_python(python_code, \"bq_script.py\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "bq_server_params = StdioServerParameters(\n",
        "    command=\"python\",\n",
        "    # Make sure to update to the full absolute path to your weather_server.py file\n",
        "    args=[\"./bq_script2.py\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running agent loop with prompt: Please list my BigQuery tables, project id is 'dw-genai-dev', location is 'us'\n",
            "Attempting to call MCP tool: 'list_tables_for_all_datasets' with args: {'project_id': 'dw-genai-dev'}\n",
            "MCP tool 'list_tables_for_all_datasets' executed successfully.\n",
            "Added 1 tool response parts to history.\n",
            "Making subsequent API call with tool responses...\n",
            "MCP tool calling loop finished. Returning final response.\n",
            "Okay, here are the tables in the project 'dw-genai-dev':\n",
            "\n",
            "Dataset: demo_dataset1\n",
            "- item_table\n",
            "- user_table\n",
            "\n",
            "Dataset: demo_dataset2\n",
            "- item_table\n",
            "- user_table\n"
          ]
        }
      ],
      "source": [
        "async def run():\n",
        "    async with stdio_client(bq_server_params) as (read, write):\n",
        "        async with ClientSession(\n",
        "            read,\n",
        "            write,\n",
        "        ) as session:\n",
        "            # Test prompt\n",
        "            prompt = \"Please list my BigQuery tables, project id is 'dw-genai-dev', location is 'us'\"\n",
        "            print(f\"Running agent loop with prompt: {prompt}\")\n",
        "            # Run agent loop\n",
        "            res = await agent_loop(prompt, client, session)\n",
        "            return res\n",
        "res = await run()\n",
        "print(res.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example 2:  Create MCP server for Medlineplus website\n",
        "Create an MCP server for \n",
        "https://medlineplus.gov/about/developers/webservices/ API service"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "med_url =\"https://medlineplus.gov/about/developers/webservices/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully fetched content\n"
          ]
        }
      ],
      "source": [
        "med_api_details = get_url_content(med_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully formatted the code and saved it to 'med.py'\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "  Please create an MCP server code for https://medlineplus.gov/about/developers/webservices/. It has one tool, get_medical_term. You provide a medical term, this tool will return explanation of the medial term\n",
        "  \n",
        "  Here's the API details:\n",
        "  {med_api_details}\n",
        "\"\"\"\n",
        "\n",
        "response_text= generate_mcp_server(prompt)\n",
        "python_code=json.loads(response_text)['python_code']\n",
        "\n",
        "format_python(python_code, \"med.py\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "med_server_params = StdioServerParameters(\n",
        "    command=\"python\",\n",
        "    # Make sure to update to the full absolute path to your weather_server.py file\n",
        "    args=[\"./med.py\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running agent loop with prompt: Please explain flu in detail.\n",
            "Attempting to call MCP tool: 'get_medical_term' with args: {'term': 'flu'}\n",
            "MCP tool 'get_medical_term' executed successfully.\n",
            "Added 1 tool response parts to history.\n",
            "Making subsequent API call with tool responses...\n",
            "MCP tool calling loop finished. Returning final response.\n",
            "Flu, also known as influenza, is a respiratory infection caused by viruses. Millions of people in the US get sick with the flu each year. While it often causes mild illness, it can sometimes be serious or even fatal, particularly for individuals over 65, newborns, and those with certain chronic health conditions.\n",
            "\n",
            "**Cause:**\n",
            "Flu is caused by influenza viruses that spread from person to person primarily through tiny droplets produced when someone with the flu coughs, sneezes, or talks. These droplets can be inhaled by people nearby. Less commonly, infection can occur by touching a contaminated surface and then touching one's own mouth, nose, or eyes.\n",
            "\n",
            "**Symptoms:**\n",
            "Flu symptoms typically appear suddenly and can include:\n",
            "*   Fever or feeling feverish/chills\n",
            "*   Cough\n",
            "*   Sore throat\n",
            "*   Runny or stuffy nose\n",
            "*   Muscle or body aches\n",
            "*   Headaches\n",
            "*   Fatigue (tiredness)\n",
            "*   Some people, especially children, may experience vomiting and diarrhea.\n",
            "\n",
            "**Flu vs. Cold:**\n",
            "It can sometimes be hard to distinguish between a cold and the flu. Key differences include:\n",
            "*   **Onset:** Flu symptoms usually come on suddenly, while cold symptoms develop slowly.\n",
            "*   **Fever:** Fever is common with the flu but rare with a cold.\n",
            "*   **Aches:** Body aches are usual with the flu, often slight with a cold.\n",
            "*   **Fatigue:** Fatigue and weakness are typical with the flu but only sometimes occur with a cold.\n",
            "*   **Headache:** Headaches are common with the flu but rare with a cold.\n",
            "*   **Stuffy nose, sneezing, sore throat:** These are common with colds but only sometimes occur with the flu.\n",
            "\n",
            "Note: \"Stomach flu\" is a term sometimes used for gastroenteritis, which is different from influenza.\n",
            "\n",
            "**Complications:**\n",
            "Some individuals may develop complications from the flu, which can be serious or life-threatening. These include:\n",
            "*   Bronchitis\n",
            "*   Ear infection\n",
            "*   Sinus infection\n",
            "*   Pneumonia\n",
            "*   Inflammation of the heart (myocarditis), brain (encephalitis), or muscle tissues (myositis, rhabdomyolysis).\n",
            "Flu can also worsen chronic health problems, like triggering asthma attacks in people with asthma.\n",
            "\n",
            "**Higher Risk Groups for Complications:**\n",
            "*   Adults 65 and older\n",
            "*   Pregnant women\n",
            "*   Children younger than 5\n",
            "*   People with chronic health conditions (e.g., asthma, diabetes, heart disease)\n",
            "\n",
            "**Diagnosis:**\n",
            "Healthcare providers diagnose the flu based on medical history and symptoms. Tests involving swabbing the inside of the nose or back of the throat can detect the flu virus. Rapid tests provide results in 15-20 minutes but are less accurate than other tests that take one to several hours.\n",
            "\n",
            "**Treatment:**\n",
            "Most people recover from the flu on their own without medical intervention. Those with mild cases should stay home and avoid contact with others (except for medical care). If you have flu symptoms and are in a high-risk group, very sick, or concerned, contact your healthcare provider. Antiviral medications may be prescribed. These drugs can lessen the severity and duration of illness and prevent serious complications, especially if started within two days of symptom onset.\n",
            "\n",
            "**Prevention:**\n",
            "*   The most effective way to prevent the flu is to get an annual flu vaccine.\n",
            "*   Good health habits, such as covering your cough and washing your hands frequently, also help prevent the spread of germs.\n"
          ]
        }
      ],
      "source": [
        "async def run():\n",
        "    async with stdio_client(med_server_params) as (read, write):\n",
        "        async with ClientSession(\n",
        "            read,\n",
        "            write,\n",
        "        ) as session:\n",
        "            # Test prompt\n",
        "            prompt = \"Please explain flu in detail.\"\n",
        "            print(f\"Running agent loop with prompt: {prompt}\")\n",
        "            # Run agent loop\n",
        "            res = await agent_loop(prompt, client, session)\n",
        "            return res\n",
        "res = await run()\n",
        "print(res.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example 3: Create MCP Server for NIH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "nih_url=\"https://clinicaltables.nlm.nih.gov/apidoc/icd10cm/v3/doc.html\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully fetched content\n"
          ]
        }
      ],
      "source": [
        "nih_api_details = get_url_content(nih_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully formatted the code and saved it to 'nih.py'\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "  Please create an MCP server code for NIH. It has one tool, get_icd_10_code. You provide a name or code, it will return top 5 results. \n",
        "  \n",
        "  Here's the API details:\n",
        "   {nih_api_details}\n",
        "\"\"\"\n",
        "\n",
        "response_text= generate_mcp_server(prompt)\n",
        "python_code=json.loads(response_text)['python_code']\n",
        "\n",
        "format_python(python_code, \"nih.py\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running agent loop with prompt: Please tell me ICD_10 code for tuberc\n",
            "Attempting to call MCP tool: 'get_icd_10_code' with args: {'query': 'tuberc'}\n",
            "MCP tool 'get_icd_10_code' executed successfully.\n",
            "Added 1 tool response parts to history.\n",
            "Making subsequent API call with tool responses...\n",
            "MCP tool calling loop finished. Returning final response.\n",
            "Okay, I can help with that. Here are the top 5 matching ICD-10-CM codes for \"tuberc\":\n",
            "\n",
            "*   **A15.0:** Tuberculosis of lung\n",
            "*   **A15.4:** Tuberculosis of intrathoracic lymph nodes\n",
            "*   **A15.5:** Tuberculosis of larynx, trachea and bronchus\n",
            "*   **A15.6:** Tuberculous pleurisy\n",
            "*   **A15.7:** Primary respiratory tuberculosis\n"
          ]
        }
      ],
      "source": [
        "nih_server_params = StdioServerParameters(\n",
        "    command=\"python\",\n",
        "    # Make sure to update to the full absolute path to your weather_server.py file\n",
        "    args=[\"./nih.py\"],\n",
        ")\n",
        "\n",
        "async def run():\n",
        "    async with stdio_client(nih_server_params) as (read, write):\n",
        "        async with ClientSession(\n",
        "            read,\n",
        "            write,\n",
        "        ) as session:\n",
        "            # Test prompt\n",
        "            prompt = \"Please tell me ICD_10 code for tuberc\"\n",
        "            print(f\"Running agent loop with prompt: {prompt}\")\n",
        "            # Run agent loop\n",
        "            res = await agent_loop(prompt, client, session)\n",
        "            return res\n",
        "res = await run()\n",
        "print(res.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "notebook_template.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
