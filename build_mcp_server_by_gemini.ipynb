{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2025 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# Use Gemini 2.5 Pro to develop MCP Server\n",
    "\n",
    "\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/wadave/vertex_ai_mcp_samples/blob/main/create_mcp_server_by_gemini.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  \n",
    "  \n",
    "  \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/wadave/vertex_ai_mcp_samples/blob/main/create_mcp_server_by_gemini.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "\n",
    "<div style=\"clear: both;\"></div>\n",
    "\n",
    "<b>Share to:</b>\n",
    "\n",
    "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/notebook_template.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/notebook_template.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/notebook_template.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/notebook_template.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/notebook_template.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84f0f73a0f76"
   },
   "source": [
    "| Author(s) |\n",
    "| --- |\n",
    "| [Dave Wang](https://github.com/wadave) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## Overview\n",
    "The Model Context Protocol (MCP) is an open standard that simplifies how AI assistants connect with external data, tools, and systems. It achieves this by standardizing the way applications provide contextual information to Large Language Models (LLMs), creating a vital interface for models to interact directly with various external services.\n",
    "\n",
    "Developers building MCP-enabled applications have the flexibility to utilize existing third-party MCP servers or implement their own custom server solutions.\n",
    "\n",
    "This notebook focuses on the latter, demonstrating how to build custom MCP servers using Gemini 2.5 Pro. We will walk through code generation and testing for three specific examples:\n",
    "\n",
    "#### MCP server code generation:\n",
    "- Example 1: Creating a BigQuery MCP Server\n",
    "- Example 2: Creating a MedlinePlus MCP Server\n",
    "- Example 3: Creating an NIH MCP Server\n",
    "\n",
    "#### MCP server code testing:\n",
    "- Option 1: Use LangChain MCP Adaptor\n",
    "- Option 2: Build your own agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61RBz8LLbxCR"
   },
   "source": [
    "## Get started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "No17Cw5hgx12"
   },
   "source": [
    "### Install Google Gen AI SDK and other required packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "tFy3H3aPgx12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet google-genai google-cloud-secret-manager mcp geopy black google-cloud-bigquery langchain-mcp-adapters langchain langchain-google-vertexai langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmWOrTJ3gx13"
   },
   "source": [
    "### Authenticate your notebook environment (Colab only)\n",
    "\n",
    "If you're running this notebook on Google Colab, run the cell below to authenticate your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NyKGtVQjgx13"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import secretmanager\n",
    "from google import genai\n",
    "import datetime\n",
    "\n",
    "from google.genai.types import (\n",
    "    GenerateContentConfig,\n",
    ")\n",
    "\n",
    "from typing import List, Dict, Any\n",
    "import json\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "import asyncio\n",
    "from google.genai import types\n",
    "from typing import List\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "# Create server parameters for stdio connection\n",
    "\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from IPython.display import display, Markdown\n",
    "from langchain_core.messages import HumanMessage, ToolMessage, AIMessage\n",
    "\n",
    "sys.path.append(os.path.abspath(\"/util\"))\n",
    "from util.util import access_secret_version, get_url_content, format_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DF4l8DTdWgPY"
   },
   "source": [
    "### Set up Vertex AI \n",
    "\n",
    "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
    "\n",
    "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "Nqwi-5ufWp_B"
   },
   "outputs": [],
   "source": [
    "# Use the environment variable if the user doesn't provide Project ID.\n",
    "import os\n",
    "from google import genai\n",
    "\n",
    "PROJECT_ID = \"[your-project-id]\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
    "if not PROJECT_ID or PROJECT_ID == \"[your-project-id]\":\n",
    "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
    "\n",
    "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Gemini client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "MODEL_ID = (\n",
    "    \"gemini-2.5-pro-exp-03-25\"  # This model is only for MCP server code generation.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get system instruction context info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The URL you want to fetch\n",
    "url = \"https://modelcontextprotocol.io/quickstart/server\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fetched content\n"
     ]
    }
   ],
   "source": [
    "reference_content = get_url_content(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up system instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class ResponseSchema(BaseModel):\n",
    "    python_code: str\n",
    "    description: str\n",
    "\n",
    "\n",
    "system_instruction = f\"\"\"\n",
    "  You are an MCP server export.\n",
    "  Your mission is to write python code for MCP server.\n",
    "  Here's the MCP server development guide and example\n",
    "  {reference_content}\n",
    "  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set function to generate MCP server code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mcp_server(prompt):\n",
    "    response = client.models.generate_content(\n",
    "        model=MODEL_ID,\n",
    "        contents=prompt,\n",
    "        config=GenerateContentConfig(\n",
    "            system_instruction=system_instruction,\n",
    "            response_mime_type=\"application/json\",\n",
    "            response_schema=ResponseSchema,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate MCP Server Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1:  Create MCP Server for Google Cloud BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "  Please create an MCP server code for google cloud big query. It has two tools. One is to list tables for all datasets, the other is to describe a table. Google cloud project id and location will be provided for use. please use project id to access big query client.\n",
    "  \n",
    "  Return Python code within a JSON object formatted exactly as: {'python_code':    'your_generated_code', 'description':'your description'}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_text = generate_mcp_server(prompt)\n",
    "python_code = json.loads(response_text)[\"python_code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully formatted the code and saved it to 'server/bq.py'\n"
     ]
    }
   ],
   "source": [
    "format_python(python_code, \"server/bq.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2:  Create MCP server for Medlineplus website\n",
    "Create an MCP server for \n",
    "https://medlineplus.gov/about/developers/webservices/ API service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fetched content\n"
     ]
    }
   ],
   "source": [
    "med_url = \"https://medlineplus.gov/about/developers/webservices/\"\n",
    "med_api_details = get_url_content(med_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully formatted the code and saved it to 'server/med.py'\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "  Please create an MCP server code for https://medlineplus.gov/about/developers/webservices/. It has one tool, get_medical_term. You provide a medical term, this tool will return explanation of the medial term\n",
    "  \n",
    "  Here's the API details:\n",
    "  {med_api_details}\n",
    "\"\"\"\n",
    "\n",
    "response_text = generate_mcp_server(prompt)\n",
    "python_code = json.loads(response_text)[\"python_code\"]\n",
    "\n",
    "format_python(python_code, \"server/med.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Create MCP Server for NIH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fetched content\n"
     ]
    }
   ],
   "source": [
    "nih_url = \"https://clinicaltables.nlm.nih.gov/apidoc/icd10cm/v3/doc.html\"\n",
    "nih_api_details = get_url_content(nih_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully formatted the code and saved it to 'server/nih.py'\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "  Please create an MCP server code for NIH. It has one tool, get_icd_10_code. You provide a name or code, it will return top 5 results. \n",
    "  \n",
    "  Here's the API details:\n",
    "   {nih_api_details}\n",
    "\"\"\"\n",
    "\n",
    "response_text = generate_mcp_server(prompt)\n",
    "python_code = json.loads(response_text)[\"python_code\"]\n",
    "\n",
    "format_python(python_code, \"server/nih.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing MCP Servers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Use LangChain MCP adaptor to test MCP servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=LOCATION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatVertexAI(\n",
    "    model=\"gemini-2.0-flash-001\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    max_retries=6,\n",
    "    stop=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_configs = {\n",
    "    \"nih\": {\n",
    "        \"command\": \"python\",\n",
    "        \"args\": [\"./server/nih.py\"],\n",
    "        \"transport\": \"stdio\",\n",
    "    },\n",
    "    \"med\": {\n",
    "        \"command\": \"python\",\n",
    "        \"args\": [\"./server/med.py\"],\n",
    "        \"transport\": \"stdio\",\n",
    "    },\n",
    "    \"bq\": {\n",
    "        \"command\": \"python\",\n",
    "        \"args\": [\"./server/bq.py\"],\n",
    "        \"transport\": \"stdio\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up MCP Client using LangChain MCP Adaptor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_lc_react_agent(server_configs, message):\n",
    "    async with MultiServerMCPClient(server_configs) as client:\n",
    "        agent = create_react_agent(llm, client.get_tools())\n",
    "        \n",
    "        agent_response = await agent.ainvoke({\"messages\": message})\n",
    "        for response in agent_response[\"messages\"]:\n",
    "            user = \"\"\n",
    "\n",
    "            if isinstance(response, HumanMessage):\n",
    "                user = \"[User]\"\n",
    "            elif isinstance(response, ToolMessage):\n",
    "                user = \"-Tool-\"\n",
    "            elif isinstance(response, AIMessage):\n",
    "                user = \"[Agent]\"\n",
    "\n",
    "            if isinstance(response.content, list):\n",
    "                display(Markdown(f'{user}: {response.content[0].get(\"text\", \"\")}'))\n",
    "                continue\n",
    "            display(Markdown(f\"{user}: {response.content}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1: BigQuery MCP server testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[User]: Please list my bigquery tables for project 'dw-genai-dev'"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[Agent]: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "-Tool-: demo_dataset1.item_table\n",
       "demo_dataset1.user_table\n",
       "demo_dataset2.item_table\n",
       "demo_dataset2.user_table"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[Agent]: OK. I found these tables in project 'dw-genai-dev':\n",
       "demo_dataset1.item_table\n",
       "demo_dataset1.user_table\n",
       "demo_dataset2.item_table\n",
       "demo_dataset2.user_table"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "await run_lc_react_agent(\n",
    "    server_configs, \"Please list my bigquery tables for project 'dw-genai-dev'\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2: MedlinePlus MCP server testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[User]: Please explain flu in details"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[Agent]: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "-Tool-: What is the <span class=\"qt0\">flu</span>?<p>The <span class=\"qt0\">flu</span>, also called <span class=\"qt0\">influenza</span>, is a respiratory infection caused by viruses. Each year, millions of Americans get sick with the <span class=\"qt0\">flu</span>. Sometimes it causes mild illness. But it can also be serious or even deadly, especially for people over 65, newborn babies, and people with certain chronic illnesses.</p>What causes the <span class=\"qt0\">flu</span>?<p>The <span class=\"qt0\">flu</span> is caused by <span class=\"qt0\">flu</span> viruses that spread from person to person. When someone with the <span class=\"qt0\">flu</span> coughs, sneezes, or talks, they spray tiny droplets. These droplets can land in the mouths or noses of people who are nearby. Less often, a person may get <span class=\"qt0\">flu</span> by touching a surface or object that has <span class=\"qt0\">flu</span> virus on it and then touching their own mouth, nose, or possibly their eyes.</p>What are the symptoms of the <span class=\"qt0\">flu</span>?<p>Symptoms of the <span class=\"qt0\">flu</span> come on suddenly and may include:</p><ul><li>Fever or feeling feverish/chills</li><li>Cough</li><li>Sore throat</li><li>Runny or stuffy nose</li><li>Muscle or body aches</li><li>Headaches</li><li>Fatigue (tiredness)</li></ul><p>Some people may also have vomiting and diarrhea. This is more common in children.</p><p>Sometimes people have trouble figuring out whether they have a cold or the <span class=\"qt0\">flu</span>. There are differences between them:</p>Signs and SymptomsColdFluStart of symptomsSlowlySuddenlyFeverRarelyUsuallyAchesSometimes (slight)UsuallyFatigue, weaknessSometimesUsuallyHeadacheRarelyCommonStuffy nose, sneezing, or sore throatCommonSometimes<p>Sometimes people say that they have a <span class=\"qt0\">\"flu\"</span> when they really have something else. For example, <span class=\"qt0\">\"stomach flu\"</span> isn't the <span class=\"qt0\">flu</span>; it's gastroenteritis.</p>What other problems can the <span class=\"qt0\">flu</span> cause?<p>Some people who get the <span class=\"qt0\">flu</span> will develop complications. Some of these complications can be serious or even life-threatening. They include:</p><ul><li>Bronchitis</li><li>Ear infection</li><li>Sinus infection</li><li>Pneumonia</li><li>Inflammation of the heart (myocarditis), brain (encephalitis), or muscle tissues (myositis, rhabdomyolysis)</li></ul><p>The <span class=\"qt0\">flu</span> also can make chronic health problems worse. For example, people with asthma may have asthma attacks while they have <span class=\"qt0\">flu</span>.</p><p>Certain people are more likely to have complications from the <span class=\"qt0\">flu</span>, including:</p><ul><li>Adults 65 and older</li><li>Pregnant women</li><li>Children younger than 5</li><li>People with certain chronic health conditions, such as asthma, diabetes, and heart disease</li></ul>How is the <span class=\"qt0\">flu</span> diagnosed?<p>To diagnose the <span class=\"qt0\">flu</span>, health care providers will first do a medical history and ask about your symptoms. There are several tests for the <span class=\"qt0\">flu</span>. For the tests, your provider will swipe the inside of your nose or the back of your throat with a swab. Then the swab will be tested for the <span class=\"qt0\">flu</span> virus.</p><p>Some tests are quick and give results in 15-20 minutes. But these tests are not as accurate as other <span class=\"qt0\">flu</span> tests. These other tests can give you the results in one hour or several hours.</p>What are the treatments for the <span class=\"qt0\">flu</span>?<p>Most people with the <span class=\"qt0\">flu</span> recover on their own without medical care. People with mild cases of the <span class=\"qt0\">flu</span> should stay home and avoid contact with others, except to get medical care.</p><p>But if you have symptoms of <span class=\"qt0\">flu</span> and are in a high risk group or are very sick or worried about your illness, contact your health care provider. You might need antiviral medicines to treat your <span class=\"qt0\">flu</span>. Antiviral medicines can make the illness milder and shorten the time you are sick. They also can prevent serious <span class=\"qt0\">flu</span> complications. They usually work best when you start taking them within 2 days of getting sick.</p>Can the <span class=\"qt0\">flu</span> be prevented?<p>The best way to prevent the <span class=\"qt0\">flu is to get a flu</span> vaccine every year. But it's also important to have good health habits like covering your cough and washing your hands often. This can help stop the spread of germs and prevent the <span class=\"qt0\">flu</span>.</p><p>Centers for Disease Control and Prevention</p>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[Agent]: The flu, also called influenza, is a respiratory infection caused by viruses. Each year, millions of Americans get sick with the flu. Sometimes it causes mild illness, but it can also be serious or even deadly, especially for people over 65, newborn babies, and people with certain chronic illnesses.\n",
       "\n",
       "The flu is caused by flu viruses that spread from person to person. When someone with the flu coughs, sneezes, or talks, they spray tiny droplets. These droplets can land in the mouths or noses of people who are nearby. Less often, a person may get flu by touching a surface or object that has flu virus on it and then touching their own mouth, nose, or possibly their eyes.\n",
       "\n",
       "Symptoms of the flu come on suddenly and may include:\n",
       "* Fever or feeling feverish/chills\n",
       "* Cough\n",
       "* Sore throat\n",
       "* Runny or stuffy nose\n",
       "* Muscle or body aches\n",
       "* Headaches\n",
       "* Fatigue (tiredness)\n",
       "\n",
       "Some people may also have vomiting and diarrhea, which is more common in children.\n",
       "\n",
       "The best way to prevent the flu is to get a flu vaccine every year. Itâ€™s also important to have good health habits like covering your cough and washing your hands often to help stop the spread of germs and prevent the flu.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "await run_lc_react_agent(server_configs, \"Please explain flu in details\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 3: NIH MCP Server testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[User]: can you tell me icd-10 code for influenza A?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[Agent]: "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "-Tool-: Code: J09.X1, Name: Influenza due to identified novel influenza A virus with pneumonia\n",
       "Code: J09.X3, Name: Influenza due to identified novel influenza A virus with gastrointestinal manifestations\n",
       "Code: J09.X9, Name: Influenza due to identified novel influenza A virus with other manifestations\n",
       "Code: J09.X2, Name: Influenza due to identified novel influenza A virus with other respiratory manifestations\n",
       "Code: A41.3, Name: Sepsis due to Hemophilus influenzae"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[Agent]: Here are some possible ICD-10 codes for Influenza A:\n",
       "J09.X1: Influenza due to identified novel influenza A virus with pneumonia\n",
       "J09.X3: Influenza due to identified novel influenza A virus with gastrointestinal manifestations\n",
       "J09.X9: Influenza due to identified novel influenza A virus with other manifestations\n",
       "J09.X2: Influenza due to identified novel influenza A virus with other respiratory manifestations\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "await run_lc_react_agent(server_configs, \"can you tell me icd-10 code for influenza A?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_streaming_agent():\n",
    "    async with MultiServerMCPClient(\n",
    "        {\n",
    "            \"nih\": {\n",
    "                \"command\": \"python\",\n",
    "                \"args\": [\"./server/nih.py\"],\n",
    "                \"transport\": \"stdio\",\n",
    "            },\n",
    "        }\n",
    "    ) as client:\n",
    "        agent = create_react_agent(llm, client.get_tools())\n",
    "        # Initialize conversation history using simple tuples\n",
    "        inputs = {\"messages\": []}\n",
    "\n",
    "        print(\"Agent is ready. Type 'exit' to quit.\")\n",
    "        while True:\n",
    "            user_input = input(\"You: \")\n",
    "            if user_input.lower() == \"exit\":\n",
    "                print(\"Exiting chat.\")\n",
    "                break\n",
    "\n",
    "            # Append user message to history\n",
    "            inputs[\"messages\"].append((\"user\", user_input))\n",
    "\n",
    "            # call our graph with streaming to see the steps\n",
    "            async for state in agent.astream(inputs, stream_mode=\"values\"):\n",
    "                last_message = state[\"messages\"][-1]\n",
    "                print(last_message)\n",
    "                last_message.pretty_print()\n",
    "\n",
    "            # update the inputs with the agent's response\n",
    "            inputs[\"messages\"] == state[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent is ready. Type 'exit' to quit.\n",
      "content='can you tell me icd-10 code for influenza A?' additional_kwargs={} response_metadata={} id='aae6f6ee-0e32-4b39-9213-a9d4247a17e2'\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "can you tell me icd-10 code for influenza A?\n",
      "content='' additional_kwargs={'function_call': {'name': 'get_icd_10_code', 'arguments': '{\"query\": \"influenza A\"}'}} response_metadata={'is_blocked': False, 'safety_ratings': [], 'usage_metadata': {'prompt_token_count': 98, 'candidates_token_count': 13, 'total_token_count': 111, 'prompt_tokens_details': [{'modality': 1, 'token_count': 98}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 13}], 'cached_content_token_count': 0, 'cache_tokens_details': []}, 'finish_reason': 'STOP', 'avg_logprobs': -0.0007394411099644807, 'model_name': 'gemini-2.0-flash-001'} id='run-df4ed000-b4bb-4018-828b-6273d9690950-0' tool_calls=[{'name': 'get_icd_10_code', 'args': {'query': 'influenza A'}, 'id': 'b725bcf5-cb12-45b6-9bc5-038cbe4e198c', 'type': 'tool_call'}] usage_metadata={'input_tokens': 98, 'output_tokens': 13, 'total_tokens': 111}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_icd_10_code (b725bcf5-cb12-45b6-9bc5-038cbe4e198c)\n",
      " Call ID: b725bcf5-cb12-45b6-9bc5-038cbe4e198c\n",
      "  Args:\n",
      "    query: influenza A\n",
      "content='Code: J09.X1, Name: Influenza due to identified novel influenza A virus with pneumonia\\nCode: J09.X3, Name: Influenza due to identified novel influenza A virus with gastrointestinal manifestations\\nCode: J09.X9, Name: Influenza due to identified novel influenza A virus with other manifestations\\nCode: J09.X2, Name: Influenza due to identified novel influenza A virus with other respiratory manifestations\\nCode: A41.3, Name: Sepsis due to Hemophilus influenzae' name='get_icd_10_code' id='5307e592-6758-4934-9a2f-6424decd787b' tool_call_id='b725bcf5-cb12-45b6-9bc5-038cbe4e198c'\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_icd_10_code\n",
      "\n",
      "Code: J09.X1, Name: Influenza due to identified novel influenza A virus with pneumonia\n",
      "Code: J09.X3, Name: Influenza due to identified novel influenza A virus with gastrointestinal manifestations\n",
      "Code: J09.X9, Name: Influenza due to identified novel influenza A virus with other manifestations\n",
      "Code: J09.X2, Name: Influenza due to identified novel influenza A virus with other respiratory manifestations\n",
      "Code: A41.3, Name: Sepsis due to Hemophilus influenzae\n",
      "content='Here are some of the ICD-10 codes for Influenza A:\\nJ09.X1: Influenza due to identified novel influenza A virus with pneumonia\\nJ09.X3: Influenza due to identified novel influenza A virus with gastrointestinal manifestations\\nJ09.X9: Influenza due to identified novel influenza A virus with other manifestations\\nJ09.X2: Influenza due to identified novel influenza A virus with other respiratory manifestations\\n' additional_kwargs={} response_metadata={'is_blocked': False, 'safety_ratings': [], 'citation_metadata': {'citations': [{'start_index': 126, 'end_index': 307, 'uri': 'http://timdietrich.me/icd-10-2017/cm/J09/', 'title': '', 'license_': ''}]}, 'usage_metadata': {'prompt_token_count': 232, 'candidates_token_count': 92, 'total_token_count': 324, 'prompt_tokens_details': [{'modality': 1, 'token_count': 232}], 'candidates_tokens_details': [{'modality': 1, 'token_count': 92}], 'cached_content_token_count': 0, 'cache_tokens_details': []}, 'finish_reason': 'STOP', 'avg_logprobs': -0.0134938164897587, 'model_name': 'gemini-2.0-flash-001'} id='run-fffcecc5-0cfc-42ed-9503-1c76ba54b8c4-0' usage_metadata={'input_tokens': 232, 'output_tokens': 92, 'total_tokens': 324}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here are some of the ICD-10 codes for Influenza A:\n",
      "J09.X1: Influenza due to identified novel influenza A virus with pneumonia\n",
      "J09.X3: Influenza due to identified novel influenza A virus with gastrointestinal manifestations\n",
      "J09.X9: Influenza due to identified novel influenza A virus with other manifestations\n",
      "J09.X2: Influenza due to identified novel influenza A virus with other respiratory manifestations\n",
      "Exiting chat.\n"
     ]
    }
   ],
   "source": [
    "await run_streaming_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Build your own agent to test MCP servers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Gemini Agent\n",
    "\n",
    "Within an MCP client session, this agent loop runs a multi-turn conversation loop with a Gemini model, handling tool calls via MCP server.\n",
    "\n",
    "This function orchestrates the interaction between a user prompt, a Gemini model capable of function calling, and a session object that provides and executes tools. It handles the cycle of:\n",
    "-  Gemini gets tool information from MCP client session\n",
    "-  Sending the user prompt (and conversation history) to the model.\n",
    "-  If the model requests tool calls, Gemini makes initial function calls to get structured data as per schema, and \n",
    "-  Sending the tool execution results back to the model.\n",
    "-  Repeating until the model provides a text response or the maximum number of tool execution turns is reached.\n",
    "-  Gemini generates final response based on tool responses and original query.\n",
    "  \n",
    "MCP integration with Gemini\n",
    "\n",
    "<img src=\"asset/mcp_tool_call.png\" alt=\"MCP with Gemini\" height=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "# Consider using a more recent/recommended model if available and suitable\n",
    "\n",
    "DEFAULT_MAX_TOOL_TURNS = 5  # Maximum consecutive turns for tool execution\n",
    "DEFAULT_INITIAL_TEMPERATURE = (\n",
    "    0.0  # Temperature for the first LLM call (more deterministic)\n",
    ")\n",
    "DEFAULT_TOOL_CALL_TEMPERATURE = (\n",
    "    1.0  # Temperature for LLM calls after tool use (potentially more creative)\n",
    ")\n",
    "\n",
    "# Make tool calls via MCP Server\n",
    "\n",
    "\n",
    "async def _execute_tool_calls(\n",
    "    function_calls: List[types.FunctionCall], session: ClientSession\n",
    ") -> List[types.Part]:\n",
    "    \"\"\"\n",
    "    Executes a list of function calls requested by the Gemini model via the session.\n",
    "\n",
    "    Args:\n",
    "        function_calls: A list of FunctionCall objects from the model's response.\n",
    "        session: The session object capable of executing tools via `call_tool`.\n",
    "\n",
    "    Returns:\n",
    "        A list of Part objects, each containing a FunctionResponse corresponding\n",
    "        to the execution result of a requested tool call.\n",
    "    \"\"\"\n",
    "    tool_response_parts: List[types.Part] = []\n",
    "    print(f\"--- Executing {len(function_calls)} tool call(s) ---\")\n",
    "\n",
    "    for func_call in function_calls:\n",
    "        tool_name = func_call.name\n",
    "        # Ensure args is a dictionary, even if missing or not a dict type\n",
    "        args = func_call.args if isinstance(func_call.args, dict) else {}\n",
    "        print(f\"  Attempting to call session tool: '{tool_name}' with args: {args}\")\n",
    "\n",
    "        tool_result_payload: Dict[str, Any]\n",
    "        try:\n",
    "            # Execute the tool using the provided session object\n",
    "            # Assumes session.call_tool returns an object with attributes\n",
    "            # like `isError` (bool) and `content` (list of Part-like objects).\n",
    "            tool_result = await session.call_tool(tool_name, args)\n",
    "            print(f\"  Session tool '{tool_name}' execution finished.\")\n",
    "\n",
    "            # Extract result or error message from the tool result object\n",
    "            result_text = \"\"\n",
    "            # Check structure carefully based on actual `session.call_tool` return type\n",
    "            if (\n",
    "                hasattr(tool_result, \"content\")\n",
    "                and tool_result.content\n",
    "                and hasattr(tool_result.content[0], \"text\")\n",
    "            ):\n",
    "                result_text = tool_result.content[0].text or \"\"\n",
    "\n",
    "            if hasattr(tool_result, \"isError\") and tool_result.isError:\n",
    "                error_message = (\n",
    "                    result_text\n",
    "                    or f\"Tool '{tool_name}' failed without specific error message.\"\n",
    "                )\n",
    "                print(f\"  Tool '{tool_name}' reported an error: {error_message}\")\n",
    "                tool_result_payload = {\"error\": error_message}\n",
    "            else:\n",
    "                print(\n",
    "                    f\"  Tool '{tool_name}' succeeded. Result snippet: {result_text[:150]}...\"\n",
    "                )  # Log snippet\n",
    "                tool_result_payload = {\"result\": result_text}\n",
    "\n",
    "        except Exception as e:\n",
    "            # Catch exceptions during the tool call itself\n",
    "            error_message = f\"Tool execution framework failed: {type(e).__name__}: {e}\"\n",
    "            print(f\"  Error executing tool '{tool_name}': {error_message}\")\n",
    "            tool_result_payload = {\"error\": error_message}\n",
    "\n",
    "        # Create a FunctionResponse Part to send back to the model\n",
    "        tool_response_parts.append(\n",
    "            types.Part.from_function_response(\n",
    "                name=tool_name, response=tool_result_payload\n",
    "            )\n",
    "        )\n",
    "    print(f\"--- Finished executing tool call(s) ---\")\n",
    "    return tool_response_parts\n",
    "\n",
    "\n",
    "async def run_agent_loop(\n",
    "    prompt: str,\n",
    "    client: genai.Client,\n",
    "    session: ClientSession,\n",
    "    model_id: str = MODEL_ID,\n",
    "    max_tool_turns: int = DEFAULT_MAX_TOOL_TURNS,\n",
    "    initial_temperature: float = DEFAULT_INITIAL_TEMPERATURE,\n",
    "    tool_call_temperature: float = DEFAULT_TOOL_CALL_TEMPERATURE,\n",
    ") -> types.GenerateContentResponse:\n",
    "    \"\"\"\n",
    "    Runs a multi-turn conversation loop with a Gemini model, handling tool calls.\n",
    "\n",
    "    This function orchestrates the interaction between a user prompt, a Gemini\n",
    "    model capable of function calling, and a session object that provides\n",
    "    and executes tools. It handles the cycle of:\n",
    "    1. Sending the user prompt (and conversation history) to the model.\n",
    "    2. If the model requests tool calls, executing them via the `session`.\n",
    "    3. Sending the tool execution results back to the model.\n",
    "    4. Repeating until the model provides a text response or the maximum\n",
    "       number of tool execution turns is reached.\n",
    "\n",
    "    Args:\n",
    "        prompt: The initial user prompt to start the conversation.\n",
    "        client: An initialized Gemini GenerativeModel client object\n",
    "\n",
    "        session: An active session object responsible for listing available tools\n",
    "                 via `list_tools()` and executing them via `call_tool(tool_name, args)`.\n",
    "                 It's also expected to have an `initialize()` method.\n",
    "        model_id: The identifier of the Gemini model to use (e.g., \"gemini-1.5-pro-latest\").\n",
    "        max_tool_turns: The maximum number of consecutive turns dedicated to tool calls\n",
    "                        before forcing a final response or exiting.\n",
    "        initial_temperature: The temperature setting for the first model call.\n",
    "        tool_call_temperature: The temperature setting for subsequent model calls\n",
    "                               that occur after tool execution.\n",
    "\n",
    "    Returns:\n",
    "        The final Response from the Gemini model after the\n",
    "        conversation loop concludes (either with a text response or after\n",
    "        reaching the max tool turns).\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the session object does not provide any tools.\n",
    "        Exception: Can potentially raise exceptions from the underlying API calls\n",
    "                   or session tool execution if not caught internally by `_execute_tool_calls`.\n",
    "    \"\"\"\n",
    "    print(\n",
    "        f\"Starting agent loop with model '{model_id}' and prompt: '{prompt[:100]}...'\"\n",
    "    )\n",
    "\n",
    "    # Initialize conversation history with the user's prompt\n",
    "    contents: List[types.Content] = [\n",
    "        types.Content(role=\"user\", parts=[types.Part(text=prompt)])\n",
    "    ]\n",
    "\n",
    "    # Ensure the session is ready (if needed)\n",
    "    if hasattr(session, \"initialize\") and callable(session.initialize):\n",
    "        print(\"Initializing session...\")\n",
    "        await session.initialize()\n",
    "    else:\n",
    "        print(\"Session object does not have an initialize() method, proceeding anyway.\")\n",
    "\n",
    "    # --- 1. Discover Tools from Session ---\n",
    "    print(\"Listing tools from session...\")\n",
    "    # Assumes session.list_tools() returns an object with a 'tools' attribute (list)\n",
    "    # Each item in the list should have 'name', 'description', and 'inputSchema' attributes.\n",
    "    session_tool_list = await session.list_tools()\n",
    "\n",
    "    if not session_tool_list or not session_tool_list.tools:\n",
    "        raise ValueError(\"No tools provided by the session. Agent loop cannot proceed.\")\n",
    "\n",
    "    # Convert session tools to the format required by the Gemini API\n",
    "    gemini_tool_config = types.Tool(\n",
    "        function_declarations=[\n",
    "            types.FunctionDeclaration(\n",
    "                name=tool.name,\n",
    "                description=tool.description,\n",
    "                parameters=tool.inputSchema,  # Assumes inputSchema is compatible\n",
    "            )\n",
    "            for tool in session_tool_list.tools\n",
    "        ]\n",
    "    )\n",
    "    print(\n",
    "        f\"Configured Gemini with {len(gemini_tool_config.function_declarations)} tool(s).\"\n",
    "    )\n",
    "\n",
    "    # --- 2. Initial Model Call ---\n",
    "    print(\"Making initial call to Gemini model...\")\n",
    "    current_temperature = initial_temperature\n",
    "    response = await client.aio.models.generate_content(\n",
    "        model=MODEL_ID,\n",
    "        contents=contents,  # Send updated history\n",
    "        config=types.GenerateContentConfig(\n",
    "            temperature=1.0,\n",
    "            tools=[gemini_tool_config],\n",
    "        ),  # Keep sending same config\n",
    "    )\n",
    "    print(\"Initial response received.\")\n",
    "\n",
    "    # Append the model's first response (potentially including function calls) to history\n",
    "    # Need to handle potential lack of candidates or content\n",
    "    if not response.candidates:\n",
    "        print(\"Warning: Initial model response has no candidates.\")\n",
    "        # Decide how to handle this - raise error or return the empty response?\n",
    "        return response\n",
    "    contents.append(response.candidates[0].content)\n",
    "\n",
    "    # --- 3. Tool Calling Loop ---\n",
    "    turn_count = 0\n",
    "    # Check specifically for FunctionCall objects in the latest response part\n",
    "    latest_content = response.candidates[0].content\n",
    "    has_function_calls = any(part.function_call for part in latest_content.parts)\n",
    "\n",
    "    while has_function_calls and turn_count < max_tool_turns:\n",
    "        turn_count += 1\n",
    "        print(f\"\\n--- Tool Turn {turn_count}/{max_tool_turns} ---\")\n",
    "\n",
    "        # --- 3.1 Execute Pending Function Calls ---\n",
    "        function_calls_to_execute = [\n",
    "            part.function_call for part in latest_content.parts if part.function_call\n",
    "        ]\n",
    "        tool_response_parts = await _execute_tool_calls(\n",
    "            function_calls_to_execute, session\n",
    "        )\n",
    "\n",
    "        # --- 3.2 Add Tool Responses to History ---\n",
    "        # Send back the results for *all* function calls from the previous turn\n",
    "        contents.append(\n",
    "            types.Content(role=\"function\", parts=tool_response_parts)\n",
    "        )  # Use \"function\" role\n",
    "        print(f\"Added {len(tool_response_parts)} tool response part(s) to history.\")\n",
    "\n",
    "        # --- 3.3 Make Subsequent Model Call with Tool Responses ---\n",
    "        print(\"Making subsequent API call to Gemini with tool responses...\")\n",
    "        current_temperature = tool_call_temperature  # Use different temp for follow-up\n",
    "        response = await client.aio.models.generate_content(\n",
    "            model=MODEL_ID,\n",
    "            contents=contents,  # Send updated history\n",
    "            config=types.GenerateContentConfig(\n",
    "                temperature=1.0,\n",
    "                tools=[gemini_tool_config],\n",
    "            ),\n",
    "        )\n",
    "        print(\"Subsequent response received.\")\n",
    "\n",
    "        # --- 3.4 Append latest model response and check for more calls ---\n",
    "        if not response.candidates:\n",
    "            print(\"Warning: Subsequent model response has no candidates.\")\n",
    "            break  # Exit loop if no candidates are returned\n",
    "        latest_content = response.candidates[0].content\n",
    "        contents.append(latest_content)\n",
    "        has_function_calls = any(part.function_call for part in latest_content.parts)\n",
    "        if not has_function_calls:\n",
    "            print(\n",
    "                \"Model response contains text, no further tool calls requested this turn.\"\n",
    "            )\n",
    "\n",
    "    # --- 4. Loop Termination Check ---\n",
    "    if turn_count >= max_tool_turns and has_function_calls:\n",
    "        print(\n",
    "            f\"Maximum tool turns ({max_tool_turns}) reached. Exiting loop even though function calls might be pending.\"\n",
    "        )\n",
    "    elif not has_function_calls:\n",
    "        print(\"Tool calling loop finished naturally (model provided text response).\")\n",
    "\n",
    "    # --- 5. Return Final Response ---\n",
    "    print(\"Agent loop finished. Returning final response.\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up MCP client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_simple_agent(server_params, query):\n",
    "    async with stdio_client(server_params) as (read, write):\n",
    "        async with ClientSession(\n",
    "            read,\n",
    "            write,\n",
    "        ) as session:\n",
    "            # Test prompt\n",
    "            prompt = query\n",
    "            print(f\"Running agent loop with prompt: {prompt}\")\n",
    "            # Run agent loop\n",
    "            res = await run_agent_loop(prompt, client, session)\n",
    "            return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bq_server_params = StdioServerParameters(\n",
    "    command=\"python\",\n",
    "    # Make sure to update to the full absolute path to your server file\n",
    "    args=[\"./server/bq.py\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_server_params = StdioServerParameters(\n",
    "    command=\"python\",\n",
    "    # Make sure to update to the full absolute path to your server file\n",
    "    args=[\"./server/med.py\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nih_server_params = StdioServerParameters(\n",
    "    command=\"python\",\n",
    "    # Make sure to update to the full absolute path to your server file\n",
    "    args=[\"./server/nih.py\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running agent loop with prompt: Please list my BigQuery tables, project id is 'dw-genai-dev', location is 'us'\n",
      "Starting agent loop with model 'gemini-2.5-pro-exp-03-25' and prompt: 'Please list my BigQuery tables, project id is 'dw-genai-dev', location is 'us'...'\n",
      "Initializing session...\n",
      "Listing tools from session...\n",
      "Configured Gemini with 2 tool(s).\n",
      "Making initial call to Gemini model...\n",
      "Initial response received.\n",
      "\n",
      "--- Tool Turn 1/5 ---\n",
      "--- Executing 1 tool call(s) ---\n",
      "  Attempting to call session tool: 'list_tables' with args: {'project_id': 'dw-genai-dev'}\n",
      "  Session tool 'list_tables' execution finished.\n",
      "  Tool 'list_tables' succeeded. Result snippet: demo_dataset1.item_table\n",
      "demo_dataset1.user_table\n",
      "demo_dataset2.item_table\n",
      "demo_dataset2.user_table...\n",
      "--- Finished executing tool call(s) ---\n",
      "Added 1 tool response part(s) to history.\n",
      "Making subsequent API call to Gemini with tool responses...\n",
      "Subsequent response received.\n",
      "Model response contains text, no further tool calls requested this turn.\n",
      "Tool calling loop finished naturally (model provided text response).\n",
      "Agent loop finished. Returning final response.\n",
      "OK. I found the following tables in the project 'dw-genai-dev':\n",
      "\n",
      "*   demo_dataset1.item_table\n",
      "*   demo_dataset1.user_table\n",
      "*   demo_dataset2.item_table\n",
      "*   demo_dataset2.user_table\n",
      "\n",
      "Please note that I couldn't filter by the 'us' location as the tool doesn't support that, so this list includes tables from all datasets within the project.\n"
     ]
    }
   ],
   "source": [
    "bq_query = (\n",
    "    \"Please list my BigQuery tables, project id is 'dw-genai-dev', location is 'us'\"\n",
    ")\n",
    "bq_res = await run_simple_agent(bq_server_params, bq_query)\n",
    "print(bq_res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running agent loop with prompt: Please explain flu in detail.\n",
      "Starting agent loop with model 'gemini-2.5-pro-exp-03-25' and prompt: 'Please explain flu in detail....'\n",
      "Initializing session...\n",
      "Listing tools from session...\n",
      "Configured Gemini with 1 tool(s).\n",
      "Making initial call to Gemini model...\n",
      "Initial response received.\n",
      "\n",
      "--- Tool Turn 1/5 ---\n",
      "--- Executing 1 tool call(s) ---\n",
      "  Attempting to call session tool: 'get_medical_term' with args: {'term': 'flu'}\n",
      "  Session tool 'get_medical_term' execution finished.\n",
      "  Tool 'get_medical_term' succeeded. Result snippet: What is the <span class=\"qt0\">flu</span>?<p>The <span class=\"qt0\">flu</span>, also called <span class=\"qt0\">influenza</span>, is a respiratory infecti...\n",
      "--- Finished executing tool call(s) ---\n",
      "Added 1 tool response part(s) to history.\n",
      "Making subsequent API call to Gemini with tool responses...\n",
      "Subsequent response received.\n",
      "Model response contains text, no further tool calls requested this turn.\n",
      "Tool calling loop finished naturally (model provided text response).\n",
      "Agent loop finished. Returning final response.\n",
      "Okay, here's a detailed explanation of the flu (influenza) based on information from MedlinePlus:\n",
      "\n",
      "**What is the flu?**\n",
      "The flu, also called influenza, is a respiratory infection caused by viruses. Millions of people get sick with the flu each year. While it often causes mild illness, it can sometimes be serious or even deadly, particularly for individuals over 65, newborn babies, and those with certain chronic health conditions.\n",
      "\n",
      "**What causes the flu?**\n",
      "Flu viruses spread from person to person primarily through tiny droplets produced when someone with the flu coughs, sneezes, or talks. These droplets can land in the mouths or noses of nearby people. Less commonly, infection can occur by touching a surface or object contaminated with the flu virus and then touching one's own mouth, nose, or eyes.\n",
      "\n",
      "**What are the symptoms?**\n",
      "Flu symptoms typically come on suddenly and can include:\n",
      "*   Fever or feeling feverish/chills\n",
      "*   Cough\n",
      "*   Sore throat\n",
      "*   Runny or stuffy nose\n",
      "*   Muscle or body aches\n",
      "*   Headaches\n",
      "*   Fatigue (tiredness)\n",
      "*   Some people, especially children, may also experience vomiting and diarrhea.\n",
      "\n",
      "**How is the flu different from a cold?**\n",
      "*   **Onset:** Flu symptoms usually start suddenly, while cold symptoms develop slowly.\n",
      "*   **Fever:** Fever is common with the flu, but rare with a cold.\n",
      "*   **Aches:** Body aches are usual with the flu, but generally slight or absent with a cold.\n",
      "*   **Fatigue/Weakness:** Fatigue is common and often significant with the flu, but usually mild with a cold.\n",
      "*   **Headache:** Headaches are common with the flu, but rare with a cold.\n",
      "*   **Stuffy nose, sneezing, sore throat:** These are common with colds but only sometimes occur with the flu.\n",
      "\n",
      "*(Note: \"Stomach flu\" is a different illness called gastroenteritis, not influenza.)*\n",
      "\n",
      "**What other problems can the flu cause?**\n",
      "Sometimes, the flu can lead to complications, some of which can be serious or life-threatening:\n",
      "*   Bronchitis\n",
      "*   Ear infection\n",
      "*   Sinus infection\n",
      "*   Pneumonia\n",
      "*   Inflammation of the heart (myocarditis), brain (encephalitis), or muscle tissues (myositis, rhabdomyolysis)\n",
      "The flu can also worsen chronic health problems, like triggering asthma attacks in people with asthma.\n",
      "\n",
      "**Who is at higher risk for complications?**\n",
      "*   Adults 65 and older\n",
      "*   Pregnant women\n",
      "*   Children younger than 5\n",
      "*   People with chronic health conditions (e.g., asthma, diabetes, heart disease)\n",
      "\n",
      "**How is the flu diagnosed?**\n",
      "Diagnosis involves reviewing your medical history and symptoms. Tests can confirm the flu virus using a swab from the inside of your nose or the back of your throat. Rapid tests give results in 15-20 minutes but may be less accurate than other tests that take one to several hours.\n",
      "\n",
      "**What are the treatments?**\n",
      "Most people recover on their own with rest and avoiding contact with others (except for medical care). If you have flu symptoms and are in a high-risk group, or if you are very sick, contact your healthcare provider. Antiviral medicines may be prescribed, which can lessen severity, shorten illness duration, and prevent serious complications. They work best when started within 2 days of getting sick.\n",
      "\n",
      "**Can the flu be prevented?**\n",
      "The most effective way to prevent the flu is to get an annual flu vaccine. Good health habits, like covering your coughs and washing your hands frequently, also help stop the spread of germs.\n"
     ]
    }
   ],
   "source": [
    "med_query = \"Please explain flu in detail.\"\n",
    "med_res = await run_simple_agent(med_server_params, med_query)\n",
    "print(med_res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running agent loop with prompt: Please tell me icd-10 code for pneumonia\n",
      "Starting agent loop with model 'gemini-2.5-pro-exp-03-25' and prompt: 'Please tell me icd-10 code for pneumonia...'\n",
      "Initializing session...\n",
      "Listing tools from session...\n",
      "Configured Gemini with 1 tool(s).\n",
      "Making initial call to Gemini model...\n",
      "Initial response received.\n",
      "\n",
      "--- Tool Turn 1/5 ---\n",
      "--- Executing 1 tool call(s) ---\n",
      "  Attempting to call session tool: 'get_icd_10_code' with args: {'query': 'pneumonia'}\n",
      "  Session tool 'get_icd_10_code' execution finished.\n",
      "  Tool 'get_icd_10_code' succeeded. Result snippet: Code: A01.03, Name: Typhoid pneumonia\n",
      "Code: A02.22, Name: Salmonella pneumonia\n",
      "Code: A54.84, Name: Gonococcal pneumonia\n",
      "Code: B01.2, Name: Varicella p...\n",
      "--- Finished executing tool call(s) ---\n",
      "Added 1 tool response part(s) to history.\n",
      "Making subsequent API call to Gemini with tool responses...\n",
      "Subsequent response received.\n",
      "Model response contains text, no further tool calls requested this turn.\n",
      "Tool calling loop finished naturally (model provided text response).\n",
      "Agent loop finished. Returning final response.\n",
      "The search returned several specific types of pneumonia caused by infections. Here are the top 5 results:\n",
      "\n",
      "1.  **A01.03**: Typhoid pneumonia\n",
      "2.  **A02.22**: Salmonella pneumonia\n",
      "3.  **A54.84**: Gonococcal pneumonia\n",
      "4.  **B01.2**: Varicella pneumonia\n",
      "5.  **B06.81**: Rubella pneumonia\n",
      "\n",
      "Pneumonia can be classified in many ways (e.g., by cause, location in the lung). The most common codes for pneumonia, especially when the specific cause isn't identified initially, often start with 'J' (e.g., J18.9 for Pneumonia, unspecified organism).\n",
      "\n",
      "Did you have a more specific type of pneumonia in mind, or would you like me to search for \"Pneumonia, unspecified\"?\n"
     ]
    }
   ],
   "source": [
    "nih_query = \"Please tell me icd-10 code for pneumonia\"\n",
    "nih_res = await run_simple_agent(nih_server_params, nih_query)\n",
    "print(nih_res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "notebook_template.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
